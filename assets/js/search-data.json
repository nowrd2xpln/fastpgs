{
  
    
        "post0": {
            "title": "Title",
            "content": "Steps Camera Calibration Distortion Correction Color &amp; Gradient Threshold Perspective Transform . import matplotlib.pyplot as plt import matplotlib.image as mpimg import numpy as np import cv2 import glob import math %matplotlib inline . image = mpimg.imread(&#39;test_images/test5.jpg&#39;) #printing out some stats and plotting print(&#39;This image is:&#39;, type(image), &#39;with dimensions:&#39;, image.shape) plt.imshow(image) # if you wanted to show a single color channel image called &#39;gray&#39;, for example, call as plt.imshow(gray, cmap=&#39;gray&#39;) . This image is: &lt;class &#39;numpy.ndarray&#39;&gt; with dimensions: (720, 1280, 3) . &lt;matplotlib.image.AxesImage at 0x7f728ae119d0&gt; . def image_info(image): # Image info img_original = mpimg.imread(os.path.join(&#39;test_images/&#39;, image)) img = np.copy(img_original) #img = mpimg.imread(os.path.join(&#39;test_images/&#39;, image)) ysize = img.shape[0] xsize = img.shape[1] if DBG_LVL: print(&#39; nFile: [&#39;, xsize, &#39;x&#39;, ysize, &#39;] &#39;, image) . Load Images . calibration_image_paths = glob.glob(&#39;./camera_cal/*.jpg&#39;) calibration_images = [] for idx, img_path in enumerate(calibration_image_paths): print(idx, img_path) for idx, img in enumerate(calibration_image_paths): calibration_images.append(plt.imread(img)) plt.imshow(calibration_images[idx]) print(idx) plt.show() . 0 ./camera_cal/calibration1.jpg 1 ./camera_cal/calibration10.jpg 2 ./camera_cal/calibration11.jpg 3 ./camera_cal/calibration12.jpg 4 ./camera_cal/calibration13.jpg 5 ./camera_cal/calibration14.jpg 6 ./camera_cal/calibration15.jpg 7 ./camera_cal/calibration16.jpg 8 ./camera_cal/calibration17.jpg 9 ./camera_cal/calibration18.jpg 10 ./camera_cal/calibration19.jpg 11 ./camera_cal/calibration2.jpg 12 ./camera_cal/calibration20.jpg 13 ./camera_cal/calibration3.jpg 14 ./camera_cal/calibration4.jpg 15 ./camera_cal/calibration5.jpg 16 ./camera_cal/calibration6.jpg 17 ./camera_cal/calibration7.jpg 18 ./camera_cal/calibration8.jpg 19 ./camera_cal/calibration9.jpg 0 . 1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . Camera Calibration . nx = 9 ny = 6 # Prepare object points objp = np.zeros((nx*ny,3), np.float32) # Initialize nx*ny points with 3 columns for x,y,z objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2) # Creates # Arrays to store object points and image points objpoints = [] # 3d points in real world space imgpoints = [] # 2d points in image plane # step through the list and search for chessboard corners columns = len(calibration_images) print(&#39;Columns &#39;, columns) found_corners = 0 failed_corners = 0 for idx, img_name in enumerate(calibration_image_paths): # Read image img_original = cv2.imread(img_name) img_copy = np.copy(img_original) img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB) fig = plt.figure(figsize=(16,6)) FIG_ROWS = 1 FIG_COLUMNS = 2 a = fig.add_subplot(FIG_ROWS,FIG_COLUMNS,1) a.set_title(&#39;Original&#39;) a.imshow(img_original) # Convert to gray img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY) # Find the chessboard corners ret, corners = cv2.findChessboardCorners(img_gray, (nx,ny), None) # If found, draw corners if ret == True: # Draw and display the corners print(idx) found_corners += 1 imgpoints.append(corners) objpoints.append(objp) cv2.drawChessboardCorners(img_copy, (nx, ny), corners, ret) else: failed_corners += 1 b = fig.add_subplot(FIG_ROWS,FIG_COLUMNS,2) b.set_title(&#39;Corners&#39;) b.imshow(img_copy) plt.suptitle(img_name, fontsize=18, y=1) print(len(objpoints),len(imgpoints)) cv2.destroyAllWindows() . Columns 20 1 2 3 4 5 6 7 8 9 10 11 12 13 16 17 18 19 17 17 . Calibrate camera . img_test = cv2.imread(&#39;./camera_cal/calibration1.jpg&#39;) img_road = cv2.imread(&#39;./test_images/straight_lines2.jpg&#39;,1) img_road_rgb = cv2.cvtColor(img_road, cv2.COLOR_BGR2RGB) # Do camera calibration given object points and image points ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img_road_rgb.shape[1], img_road_rgb.shape[0]), None, None) # Correct distortion img_dst = cv2.undistort(img_test, mtx, dist, None, mtx) img_road_dst = cv2.undistort(img_road_rgb, mtx, dist, None, mtx) # Visualize undistortion f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10)) ax1.imshow(img_test) ax1.set_title(&#39;Original Image&#39;, fontsize=30) ax2.imshow(img_dst) ax2.set_title(&#39;Undistorted Image&#39;, fontsize=30) f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10)) ax1.imshow(img_road_rgb) ax1.set_title(&#39;Original Road Image&#39;, fontsize=30) ax2.imshow(img_road_dst) ax2.set_title(&#39;Undistorted Road Image&#39;, fontsize=30) . Text(0.5, 1.0, &#39;Undistorted Road Image&#39;) . Change Color Space . test_image_paths = glob.glob(&#39;./test_images/*.jpg&#39;) images = [plt.imread(file) for file in glob.glob(&#39;./test_images/*.jpg&#39;)] print(&quot;Images discoved: %d n&quot; % (len(images))) plt.imshow(images[7]) # color_spaces = [0,2,4,6,12,22,32,36,40,44,50,53,66,68,82,128,132] # fig, axes = plt.subplots(figsize=(25,14),nrows=8, ncols=len(color_spaces)) color_spaces = [4,40,50,52] color_spaces_dict = {&#39;COLOR_RGB2BGR&#39; : 4, &#39;COLOR_RGB2HSV&#39; : 41, &#39;COLOR_RGB2Lab&#39; : 45, &#39;COLOR_RGB2Luv&#39; : 51, &#39;COLOR_RGB2HLS&#39; : 53, &#39;COLOR_RGB2YUV&#39; : 83} # fig, axes = plt.subplots(figsize=(25,14),nrows=8, ncols=4) # for idx,ax in enumerate(axes.flat, start=0): # print(idx) # img = cv2.cvtColor(images[idx], color_spaces[1]) # # print(images[idx].shape, img.shape) # ax.set_title(idx) # ax.imshow(img) fig = plt.figure(figsize=(24,20)) COLS = len(color_spaces_dict) ROWS = len(images) new_image_colorspaces = [] for i,img in enumerate(images): for j,color_space in enumerate(color_spaces_dict): img_new_color = cv2.cvtColor(img,color_spaces_dict[color_space]) ax = fig.add_subplot(ROWS,COLS,i*COLS+j+1) ax.set_title(color_space) ax.imshow(img_new_color) new_image_colorspaces.append(img_new_color) fig.tight_layout() . Images discoved: 8 . len(new_image_colorspaces) fig2 = plt.figure(figsize=(50,200)) for cnt,f in enumerate(test_image_paths): print(cnt) COLS = 5 ROWS = len(new_image_colorspaces) print(ROWS, COLS) for i,img in enumerate(new_image_colorspaces, start=0): ch0 = img[:,:,0] ch1 = img[:,:,1] ch2 = img[:,:,2] print(i, i*COLS+1) ab = fig2.add_subplot(ROWS,COLS,i*COLS+1) ab.set_title(&#39;Color Space Transform&#39;) ab.imshow(img, aspect=&#39;auto&#39;) plt.axis(&#39;off&#39;) ac = fig2.add_subplot(ROWS,COLS,i*COLS+2) ac.set_title(&#39;Channel 0&#39;) ac.imshow(ch0, aspect=&#39;auto&#39;) plt.axis(&#39;off&#39;) ad = fig2.add_subplot(ROWS,COLS,i*COLS+3) ad.set_title(&#39;Channel 1&#39;) ad.imshow(ch1, aspect=&#39;auto&#39;) plt.axis(&#39;off&#39;) ae = fig2.add_subplot(ROWS,COLS,i*COLS+4) ae.set_title(&#39;Channel 2&#39;) ae.imshow(ch2, aspect=&#39;auto&#39;) plt.axis(&#39;off&#39;) . 0 1 2 3 4 5 6 7 48 5 0 1 1 6 2 11 3 16 4 21 5 26 6 31 7 36 8 41 9 46 10 51 11 56 12 61 13 66 14 71 15 76 16 81 17 86 18 91 19 96 20 101 21 106 22 111 23 116 24 121 25 126 26 131 27 136 28 141 29 146 30 151 31 156 32 161 33 166 34 171 35 176 36 181 37 186 38 191 39 196 40 201 41 206 42 211 43 216 44 221 45 226 46 231 47 236 . def color_threshold(img): img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS) img_size = (img.shape[1], img.shape[0]) # Color thresholds r_thr_min = 225 r_thr_max = 255 s_thr_min = 100 s_thr_max = 255 # Red color threshold r_channel = img[:,:,0] img_bin_r = np.zeros_like(r_channel) img_bin_r[(r_channel &gt; r_thr_min) &amp; (r_channel &lt;= r_thr_max)] = 1 # Saturation color threshold s_channel = img_hls[:,:,2] # HLS color threshold img_bin_s = np.zeros_like(r_channel) img_bin_s[(s_channel &gt; s_thr_min) &amp; (s_channel &lt;= s_thr_max)] = 1 # Stack the binary thresholds color_binary = np.dstack(( np.zeros_like(img_bin_s), img_bin_r, img_bin_s)) * 255 # DEBUG Red and HLS Filters # plt.imshow(img_bin_r) # plt.show() # plt.imshow(img_bin_s) # plt.show() # plt.imshow(color_binary) # plt.show() # Combine the binary thresholds # combined_binary = # plt.title(&#39;Original Image&#39;) # plt.imshow(img) # plt.axis(&#39;off&#39;) # plt.show() # plt.title(&#39;R Channel Image&#39;) # plt.imshow(r_channel, cmap=&#39;gray&#39;) # plt.axis(&#39;off&#39;) # plt.show() # plt.title(&#39;Binary R Channel Image&#39;) # plt.imshow(img_bin_r, cmap=&#39;gray&#39;) # plt.axis(&#39;off&#39;) # plt.show() # plt.title(&#39;HLS Image&#39;) # plt.imshow(img_hls) # plt.axis(&#39;off&#39;) # plt.show() # plt.title(&#39;S Channel Image&#39;) # plt.imshow(s_channel, cmap=&#39;gray&#39;) # plt.axis(&#39;off&#39;) # plt.show() # plt.title(&#39;Binary S Channel Image&#39;) # plt.imshow(img_bin_s, cmap=&#39;gray&#39;) # plt.axis(&#39;off&#39;) # plt.show() # Various Image Channels # f, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(24, 9)) # f.tight_layout() # ax1.set_title(&#39;Original Image&#39;) # ax1.axis(&#39;off&#39;) # ax1.imshow(img) # ax2.set_title(&#39;R Channel Image&#39;) # ax1.axis(&#39;off&#39;) # ax2.imshow(r_channel, cmap=&#39;gray&#39;) # ax3.set_title(&#39;Binary R Channel Image&#39;) # ax3.axis(&#39;off&#39;) # ax3.imshow(img_bin_r, cmap=&#39;gray&#39;) # ax4.set_title(&#39;HLS Image&#39;) # ax4.axis(&#39;off&#39;) # ax4.imshow(img_hls, cmap=&#39;gray&#39;) # ax5.set_title(&#39;S Channel Image&#39;) # ax5.axis(&#39;off&#39;) # ax5.imshow(s_channel, cmap=&#39;gray&#39;) # ax6.set_title(&#39;Binary S Channel Image&#39;) # ax6.axis(&#39;off&#39;) # ax6.imshow(img_bin_s, cmap=&#39;gray&#39;) # plt.show() return color_binary #color_threshold(images[6]) . def abs_sobel_thresh(img, orient=&#39;x&#39;, thresh_min=0, thresh_max=255): # Convert to grayscale gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Apply x or y gradient with the OpenCV Sobel() function # and take the absolute value if orient == &#39;x&#39;: abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0)) if orient == &#39;y&#39;: abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1)) # Rescale back to 8 bit integer scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel)) # Create a copy and apply the threshold binary_output = np.zeros_like(scaled_sobel) # Here I&#39;m using inclusive (&gt;=, &lt;=) thresholds, but exclusive is ok too binary_output[(scaled_sobel &gt;= thresh_min) &amp; (scaled_sobel &lt;= thresh_max)] = 1 # Return the result return binary_output # Define a function to return the magnitude of the gradient # for a given sobel kernel size and threshold values def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)): # Convert to grayscale gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Take both Sobel x and y gradients sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel) sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel) # Calculate the gradient magnitude gradmag = np.sqrt(sobelx**2 + sobely**2) # Rescale to 8 bit scale_factor = np.max(gradmag)/255 gradmag = (gradmag/scale_factor).astype(np.uint8) # Create a binary image of ones where threshold is met, zeros otherwise binary_output = np.zeros_like(gradmag) binary_output[(gradmag &gt;= mag_thresh[0]) &amp; (gradmag &lt;= mag_thresh[1])] = 1 # Return the binary image return binary_output def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)): # Grayscale gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # Calculate the x and y gradients sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel) sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel) # Take the absolute value of the gradient direction, # apply a threshold, and create a binary image result absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx)) binary_output = np.zeros_like(absgraddir) binary_output[(absgraddir &gt;= thresh[0]) &amp; (absgraddir &lt;= thresh[1])] = 1 # Return the binary image return binary_output for i,img in enumerate(images): img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) sx = abs_sobel_thresh(img, &#39;x&#39;, 10,100) sy = abs_sobel_thresh(img, &#39;y&#39;, 25,150) mxy = mag_thresh(image, sobel_kernel=7, mag_thresh=(30, 100)) dxy = dir_threshold(image, sobel_kernel=15, thresh=(0.7, 1.3)) plt.imshow(dxy) plt.title(&#39;dxy&#39;) plt.show() plt.imshow(mxy) plt.title(&#39;mxy&#39;) plt.show() plt.imshow(sx) plt.title(&#39;sx&#39;) plt.show() plt.imshow(sy) plt.title(&#39;sy&#39;) plt.show() combined = np.zeros_like(dxy) combined[((sx == 1) &amp; (sy == 1)) | ((mxy == 1) &amp; (dxy == 1))] = 1 plt.imshow(combined) plt.title(&#39;combined&#39;) plt.show() f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9)) f.tight_layout() ax1.imshow(img) ax1.set_title(&#39;Original Image&#39;, fontsize=50) ax2.imshow(combined, cmap=&#39;gray&#39;) ax2.set_title(&#39;Thresholded Grad. Dir.&#39;, fontsize=50) plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.) plt.show() . Perspective Transform . img_str_line = cv2.imread(&#39;./test_images/straight_lines1.jpg&#39;) img_str_line = cv2.cvtColor(img_str_line, cv2.COLOR_BGR2RGB) plt.imshow(img_str_line) plt.show() # Defining a four sided polygon to mask imshape = img_str_line.shape pt_topleft = (633, 425) pt_topright = (645, 425) pt_bottomleft = (203, imshape[0]) pt_bottomright = (imshape[1]-172, imshape[0]) vertices = np.array([[pt_bottomleft, pt_topleft, pt_topright, pt_bottomright]], dtype=np.int32) testimg = cv2.polylines(img_str_line, vertices, True, (0,255, 0), 2) plt.imshow(testimg) plt.show() # src = np.float32([pt_topleft, # pt_topright, # pt_bottomleft, # pt_bottomright]) # dst = np.float32([(190,0), # (1280-150,0), # (1280-150,720), # (190,720)]) offset = 100 src = np.float32([[627,425+offset], [649,425+offset], [1200,780], [180,740]]) dst = np.float32([(0,0),(1200,0),(1280/4*3,719),(1280/4*1,719)]) src2 = np.float32([(582,460), (207,720), (1110,720), (700,460)]) dst2 = np.float32([(320,0), (320,720), (960,720), (960,0)]) img_size = (img_str_line.shape[1], img_str_line.shape[0]) M = cv2.getPerspectiveTransform(src2, dst2) warped = cv2.warpPerspective(img_str_line, M, img_size,flags=cv2.INTER_LINEAR) plt.imshow(warped) warped = cv2.line(warped, (1280//4*1, 0), (1280//4*1,719), (0,0,255), 3) warped = cv2.line(warped, (1280//4*3, 0), (1280//4*3,719), (0,0,255), 3) plt.imshow(warped) . &lt;matplotlib.image.AxesImage at 0x7f724c05d450&gt; . color_bins = [] for i,img in enumerate(images): # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Original image #plt.imshow(img) #plt.show() # Remove distortion img_undst = cv2.undistort(img, mtx, dist, None, mtx) #plt.imshow(img_undst) #plt.show() # Warp Perspective img_warped = cv2.warpPerspective(img_undst, M, img_size,flags=cv2.INTER_LINEAR) plt.imshow(img_warped, cmap=&#39;gray&#39;) plt.show() # plt.imshow(color_threshold(img_warped)) color_bins.append(color_threshold(img_warped)) plt.imshow(color_bins[i], cmap=&#39;gray&#39;) plt.show() . Sliding Window . def find_lane_pixels(binary_warped): # Take a histogram of the bottom half of the image histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0) # Create an output image to draw on and visualize the result out_img = np.dstack((binary_warped, binary_warped, binary_warped)) # Find the peak of the left and right halves of the histogram # These will be the starting point for the left and right lines midpoint = np.int(histogram.shape[0]//2) leftx_base = np.argmax(histogram[:midpoint]) rightx_base = np.argmax(histogram[midpoint:]) + midpoint # HYPERPARAMETERS # Choose the number of sliding windows nwindows = 9 # Set the width of the windows +/- margin margin = 100 # Set minimum number of pixels found to recenter window minpix = 50 # Set height of windows - based on nwindows above and image shape window_height = np.int(binary_warped.shape[0]//nwindows) # Identify the x and y positions of all nonzero pixels in the image nonzero = binary_warped.nonzero() nonzeroy = np.array(nonzero[0]) nonzerox = np.array(nonzero[1]) # Current positions to be updated later for each window in nwindows leftx_current = leftx_base rightx_current = rightx_base # Create empty lists to receive left and right lane pixel indices left_lane_inds = [] right_lane_inds = [] # Step through the windows one by one for window in range(nwindows): # Identify window boundaries in x and y (and right and left) win_y_low = binary_warped.shape[0] - (window+1)*window_height win_y_high = binary_warped.shape[0] - window*window_height win_xleft_low = leftx_current - margin win_xleft_high = leftx_current + margin win_xright_low = rightx_current - margin win_xright_high = rightx_current + margin # Draw the windows on the visualization image cv2.rectangle(out_img,(win_xleft_low,win_y_low), (win_xleft_high,win_y_high),(0,255,0), 2) cv2.rectangle(out_img,(win_xright_low,win_y_low), (win_xright_high,win_y_high),(0,255,0), 2) # Identify the nonzero pixels in x and y within the window # good_left_inds = ((nonzeroy &gt;= win_y_low) &amp; (nonzeroy &lt; win_y_high) &amp; (nonzerox &gt;= win_xleft_low) &amp; (nonzerox &lt; win_xleft_high)).nonzero()[0] good_right_inds = ((nonzeroy &gt;= win_y_low) &amp; (nonzeroy &lt; win_y_high) &amp; (nonzerox &gt;= win_xright_low) &amp; (nonzerox &lt; win_xright_high)).nonzero()[0] # Append these indices to the lists left_lane_inds.append(good_left_inds) right_lane_inds.append(good_right_inds) # If you found &gt; minpix pixels, recenter next window on their mean position if len(good_left_inds) &gt; minpix: leftx_current = np.int(np.mean(nonzerox[good_left_inds])) if len(good_right_inds) &gt; minpix: rightx_current = np.int(np.mean(nonzerox[good_right_inds])) # Concatenate the arrays of indices (previously was a list of lists of pixels) try: left_lane_inds = np.concatenate(left_lane_inds) right_lane_inds = np.concatenate(right_lane_inds) except ValueError: # Avoids an error if the above is not implemented fully pass # Extract left and right line pixel positions leftx = nonzerox[left_lane_inds] lefty = nonzeroy[left_lane_inds] rightx = nonzerox[right_lane_inds] righty = nonzeroy[right_lane_inds] return leftx, lefty, rightx, righty, out_img def fit_polynomial(binary_warped): # Find our lane pixels first leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped) # Fit a second order polynomial to each using `np.polyfit` left_fit = np.polyfit(lefty, leftx, 2) right_fit = np.polyfit(righty, rightx, 2) # Generate x and y values for plotting ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] ) try: left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2] right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2] except TypeError: # Avoids an error if `left` and `right_fit` are still none or incorrect print(&#39;The function failed to fit a line!&#39;) left_fitx = 1*ploty**2 + 1*ploty right_fitx = 1*ploty**2 + 1*ploty ## Visualization ## # Colors in the left and right lane regions out_img[lefty, leftx] = [255, 0, 0] out_img[righty, rightx] = [0, 0, 255] # Plots the left and right polynomials on the lane lines plt.plot(left_fitx, ploty, color=&#39;yellow&#39;) plt.plot(right_fitx, ploty, color=&#39;yellow&#39;) return out_img print(len(color_bins)) for i in range(0, len(color_bins)): plt.imshow(color_bins[i]) plt.show() #out_img = fit_polynomial(color_bins[0]) #plt.imshow(out_img) #plt.show() . 8 .",
            "url": "https://nowrd2xpln.github.io/fastpgs/2021/01/06/adv_lane_lines.html",
            "relUrl": "/2021/01/06/adv_lane_lines.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nowrd2xpln.github.io/fastpgs/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://nowrd2xpln.github.io/fastpgs/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nowrd2xpln.github.io/fastpgs/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nowrd2xpln.github.io/fastpgs/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}